Title: Bericht MLUGS Treffen im November 2017
Date: 2017-11-21 18:30

## Protokoll

### Vorstellungsrunde

- Michael; AX Semantics; Software-Entwickler
- Andreas; AX Semantics; Software-Entwickler
- Uwe;ST2C;macht Raumfahrt
- Wilhelm;privat;Software-Entwickler
- Silvana;;Data-Scientist,eigentlich NLP
- Jörg;privat;Finanz-ML


### Uwe Sterr - Entity Embeddings of Categorical Variables

- [https://arxiv.org/pdf/1604.06737.pdf](https://arxiv.org/pdf/1604.06737.pdf)
- Slides: [https://github.com/mlugs/website/tree/master/website/content/pdfs/Entity Embeddings of Categorical Variables.pdf](https://github.com/mlugs/website/tree/master/website/content/pdfs/Entity%20Embeddings%20of%20Categorical%20Variables.pdf)


- wird in Lesson 14 im Fast.AI Kurs besprochen: [http://course.fast.ai/lessons/lesson14.html](http://course.fast.ai/lessons/lesson14.html)
- dritter platz kaggle rossmann sales prediction
- verwendet DNN - relativ simples model
- nach dem one-hot-encoding wird eine entity embeddings layer gelegt
- EE dimensions-anzahl ist ausprobieren
- auch mit einfacheren verfahren hilft EE zu besseren ergebnissen, i.e. gradient bootesd trees
- es hilft eigentlich immer, tage/monate/jahre als einzelfeatures und categoricals machen
- auch ein gutes feature sind zeiträume; i.e. wann war die letzte wartung
- [https://github.com/uwesterr/courses/blob/master/deeplearning2/rossmanWorksWithTF1.4.ipynb](https://github.com/uwesterr/courses/blob/master/deeplearning2/rossmanWorksWithTF1.4.ipynb)
- das kann man damit vielleicht mal probieren: [https://www.kaggle.com/c/favorita-grocery-sales-forecasting](https://www.kaggle.com/c/favorita-grocery-sales-forecasting)


### mlugs 2018

- nächster Termin Januar
- meetup statt letsmeet yay/nay?  yay
- Termine vorher anlegen/announcen!
- das schwere sind die Vorträge


### Wilhelm Brasch - OCR mit Deep Learning

* privates DL projekt
* chinesische untertitel erkennung
* fast alle chinesischen videos haben untertitel und diese entsprechen meist der gesprochenen Sprache
* ziel ist es 3000 schriftzeichen zu können (als chinesischlernender)
* trainingsset: 1000/kategorie -> 10000 kategorien -> 10mio
* generator kann unendlich viele daten erzeugen
* der generator mit freetype; opencv/numpy
* wichtig am model: batchnorm; relu
* deutliche verbesserung brachte ein streifen generator
* aktuell 99% accuracy
* mit sliding window über den text. viele false positives

* plan: mehr validierungsdaten; zusätzlich zur classification noch eine zeichendetection
* andere idee: regression head, um den hintergrund rauszufiltern


### Michael Käufl - Hidden Technical Debt in Machine Learning Systems

* https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf
* von google
* 9 Abschnitte
* das teure ist die Wartung nicht die Entwicklung
* "technical dept" soll die langzeitkosten aufzeigen
* die gefahr liegt in der "hidden technical dept"
* ziel vom abbau der technischen schuld ist bessere wartbarkeit zu bekommen
* change anything changes everything
* ein feature hinzufügen/modifizieren/entfernen kann das ganze model verändern
* correction cascades: z.b. lernen einer korrektur auf basis eines ursprungsmodels. wenn man allerdings das ursprungsmodel anpasst, dann hat man probleme mit dem darauf aufbauenden model
* unklare consumer. visibility dept!
* data dependencies können sich wie building dept verhalten. vor allem weil das tooling noch nicht so gut ist
* unstable data dependencies durch versionierung/tagging lösen
* ML anti-patterns:
  * glue code - wechsel zu anderen packages ist schwerer -> common apis verwenden/entwickeln
  * pipeline jungles - datenaufbereiten ist das häufiger
  * dead experimental codepaths
  * abstraction dept - es gibt noch keine basic abstraction für ML
  * multi-language-smell
  * prototype-smell - weiterverwendung des prototyps
* configuration dept - häufig nachrangig behandelte konfiguration
* wie verhalten sich manuell gewählte thresholds auf real-world-probleme und veränderungen
* monitoring + testing: prediction bias / action limits / up-stream producers (hat sich die qualität der fremd-daten verändert?)
* reproducibility dept
* cultural dept: ML research vs. engineering

* conclusion:
  * time for new algorithmus to full scale test?
  * wie schnell können neue mitarbeiter auf den aktuellen stand gebracht werden?
